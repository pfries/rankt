#!/usr/bin/env python
# -- coding: utf-8 --
from __future__ import print_function
from collections import namedtuple
from datetime import datetime
from query import Query
from snapshot import Snapshot, diff_last_two
from snapshot import diff_last_two
from store import store
from parser import parse
from hashlib import sha1
import os, json, time, sys, yaml, difflib, copy

def initialized():
    return os.path.exists('config.yml')

def init(args):
    if initialized():
        raise RuntimeError(
        'Directory already initialized -- rm config.yml to re-initialize.')

    with open(args.master_config) as f:
        config = yaml.load(f)
        cases_path = config['cases_path'] or 'cases'
        try:
            os.makedirs(cases_path)
        except OSError:
            raise RuntimeError('Found cases. Aborting.')

        project_config = {
                'project_name': args.project_name,
                'search_url': args.search_url
                }
        
        with open('config.yml', 'w') as c:
            c.write(yaml.dump(project_config, default_flow_style=False))

def create(args):
    if not initialized():
        raise Exception('Must initialize project before creating case')

    config = make_config(args)
    try:
        os.makedirs(config['queries_path'])

        default_keywords = os.path.join(config['case_path'], 'keywords')
        if args.keywords:
            with open(args.keywords) as f:
                with open(default_keywords, 'w') as q:
                    for line in f:
                        q.write(line)
        elif not sys.stdin.isatty():
            with open(default_keywords, 'w') as q:
                for line in sys.stdin:
                    q.write(line)

    except OSError as ose:
        raise RuntimeError('Cannot create case.') from ose

def snapshot(args):
    args.run_datetime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
    args.run_timestamp = str(int(time.time()))

    config = make_config(args)
    config['query'] = parse_queries(config['query'])

    ss = Snapshot(config).snapshot()
    print(json.dumps(ss))

def diff(args):
    args.run_datetime = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
    args.run_timestamp = str(int(time.time()))

    config = make_config(args)
    config['query'] = parse_queries(config['query'])

    #d = diff_last_two(config['project'], config['case'], config['store_endpoint'])
    queries = copy.deepcopy(config['query'])
    if len(queries) != 2:
        raise ValueError('Diff requires two queries')

    snapshots = []
    for q in queries:
        config['query'] = [q]
        ss = Snapshot(config).snapshot()
        snapshots.append(ss)

    differ = difflib.SequenceMatcher()
    snapshot1,snapshot2 = tuple(snapshots)
    kw_churn = [] 
    for idx, kw in enumerate(snapshot1):
        seq1 = []
        current_kw = ''
        for doc in kw:
            seq1.append(doc['documentid'])
            current_kw = doc['keywords']
        seq1 = tuple(seq1)

        kw2 = snapshot2[idx]
        seq2 = []
        for doc in kw2:
            seq2.append(doc['documentid'])
        seq2 = tuple(seq2)

        differ.set_seqs(seq1,seq2)
        unordered_similarity = differ.ratio()
        differ.set_seqs(sorted(seq1),sorted(seq2))
        sorted_similarity = differ.ratio()
        insertions = len(set(seq1) - set(seq2))
        churn_score = unordered_similarity * (1/insertions if insertions > 0 else 1)

        kw_churn.append({
                "keywords": current_kw,
                "similarity": unordered_similarity,
                "sorted_similarity": sorted_similarity,
                "insertions": insertions,
                "churn_score": churn_score
                })

    print(json.dumps(kw_churn))

def parse_queries(query_args):
    queries = []
    for q in query_args:
        args = q.split('=')
        query = {
                'query_template': args[0]
                }
        if(len(args) > 1):
            # has query template args
            query['query_args'] = json.loads(args[1])
        queries.append(query)
    return queries

def make_config(args):
    with open(args.master_config) as m, open('config.yml') as p:
        config = yaml.load(m)
        project_config = yaml.load(p)
        config.update(project_config)
        config.update(vars(args))
        keywords = []
        if args.keywords:
            with open(args.keywords) as f:
                for kw in f:
                    keywords.append(kw)
        elif not sys.stdin.isatty():
            for kw in sys.stdin:
                keywords.append(kw)
        
        config['keywords'] = keywords
        if args.__dict__.get('case'):
            config['case'] = args.case
            config['case_path'] = os.path.join(config['cases_path'], args.case)
            config['queries_path'] = os.path.join(config['case_path'], config['queries_path'])
        return config

def format_output(response, format):
    if format == 'json':
        return json.dumps(parse(response))
    elif format == 'text':
        return str(parse(response))
    else:
        print(response)

def query(args):
    try:
        config = make_config(args)
        query = Query(config['queries_path'])
        query.load_query(config['query'])
        if args.keywords:
            with open(args.keywords) as f:
                for keywords in f:
                    keywords = keywords.strip()
                    kw = keywords.split()
                    qs = query.render(keywords=kw)
                    r = query.fetch(config['search_url'], config.get('optional_params',{}), qs)
                    sys.stdout.write(format_output(r, args.output))
        elif not sys.stdin.isatty():
            for keywords in sys.stdin:
                    keywords = keywords.strip()
                    kw = keywords.split()
                    qs = query.render(keywords=kw)
                    r = query.fetch(config['search_url'], config.get('optional_params',{}), qs)
                    sys.stdout.write(format_output(r, args.output))
        else:
            raise RuntimeError('Missing keywords.')
    except Exception as e:
        raise RuntimeError('An error occured.') from e


def store_document(args):
    config = make_config(args)

    for j in sys.stdin:
        docs = json.loads(j)
        for doc in docs:
            joined_id = '{}{}{}{}{}'.format(
                    doc['project'],
                    doc['case'],
                    doc['keywords'],
                    doc['snapshot'],
                    doc['documentid'])
        
            hashed_id = sha1(joined_id.encode()).hexdigest()
            endpoint = '/'.join([config['store_endpoint'], args.store_type, hashed_id])
            store(endpoint, doc)

def main():
    import argparse

    master_config = os.path.join(
            os.path.expanduser('~'),
            '.rankt/config.yml')

    parser = argparse.ArgumentParser()
    parser.add_argument('--config', '-c', dest='master_config', default=master_config)
    subparsers = parser.add_subparsers()

    init_parser = subparsers.add_parser('init', help='initialize a project')
    init_parser.add_argument('--search-url', '-u', required=True)
    init_parser.add_argument('project', nargs='?',
            default=os.path.basename(os.getcwd()), 
            help='name of the project (default: pwd)'
            )
    init_parser.set_defaults(func=init)

    create_parser = subparsers.add_parser('create', help='create a new case')
    create_parser.add_argument('case', help='the name of the case')
    create_parser.add_argument('--keywords', '-k', nargs='?')
    create_parser.set_defaults(func=create)

    snapshot_parser = subparsers.add_parser('snapshot', help='snapshot a case')
    snapshot_parser.add_argument('case', help='the case to snapshot')
    snapshot_parser.add_argument('query', nargs='+', help='the queries to snapshot')
    snapshot_parser.add_argument('--size', '-s', help='number of docs to fetch')
    snapshot_parser.add_argument('--keywords', '-k', nargs='?')
    snapshot_parser.add_argument('-t', '--tags', nargs='*', help='tag for snapshot')
    snapshot_parser.set_defaults(func=snapshot)

    query_parser = subparsers.add_parser('query', help='query the search engine')
    query_parser.add_argument('case', help='the case to snapshot')
    query_parser.add_argument('query', help='the query to snapshot')
    query_parser.add_argument('--size', '-s', help='number of docs to fetch')
    query_parser.add_argument('--keywords', '-k', nargs='?')
    query_parser.add_argument('--output', '-o', nargs=1,
            choices=['json','text'], default='json')
    query_parser.add_argument('--explain-only', '-E')
    query_parser.set_defaults(func=query)

    diff_parser = subparsers.add_parser('diff', help='diff search results')
    diff_parser.add_argument('case', help='the case to snapshot')
    diff_parser.add_argument('query', nargs='+', help='the queries to snapshot')
    diff_parser.add_argument('--size', '-s', help='number of docs to fetch')
    diff_parser.add_argument('--keywords', '-k', nargs='?')
    diff_parser.set_defaults(func=diff)

    store_parser = subparsers.add_parser('store', help='store documents')
    store_parser.add_argument('store_type', help='the type of the document')
    store_parser.set_defaults(func=store_document)

    args = parser.parse_args()
    args.func(args)

if __name__ == '__main__':
    main()
